# Configuration for prompts
prompts:
  receipt_processing: {}
  text_analysis: {}

models:
  default: qwen2-vl-7b-instruct

settings:
  temperature: 0.7
  max_tokens: 2048